{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2cd9597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from math import e\n",
    "Nr=4;Nt=4;M=128\n",
    "channel = torch.from_numpy(np.load('noisechannel.npy',allow_pickle=True))\n",
    "dlink = torch.from_numpy(np.load('directlink.npy',allow_pickle=True))\n",
    "rlink = torch.from_numpy(np.load('receiverlink.npy',allow_pickle=True))\n",
    "tlink = torch.from_numpy(np.load('transmitterlink.npy',allow_pickle=True))\n",
    "ochannel = channel.view(18100,Nr**2,Nt**2)\n",
    "dchannel = dlink.view(18100,Nr**2,Nt**2)\n",
    "rchannel = rlink.view(18100,Nr**2,M)     \n",
    "tchannel = tlink.view(M,Nt**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc8aa4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(192, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "K =4\n",
    "M=128\n",
    "#transmit power covariance matrix\n",
    "Pt = 20 # in watts\n",
    "P_noise = 10**-14\n",
    "P = (Pt/K*torch.eye(K))\n",
    "Q = torch.sqrt(P)\n",
    "Qinv = torch.linalg.inv(Q)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# phase inilization\n",
    "phi = (1j*torch.ones(M,dtype=torch.cdouble)).to(device)\n",
    "phi_inv = (1/phi).to(device)\n",
    "phi = torch.diag(phi)\n",
    "phi_inv = torch.diag(phi_inv)\n",
    "rand_phi = ((torch.rand(M,dtype=torch.cdouble)+1j*torch.rand(M,dtype=torch.cdouble)-0.5-1j*0.5)*2).to(device)\n",
    "rand_phi = rand_phi/abs(rand_phi).to(device)\n",
    "rand_phi = torch.diag(rand_phi).to(device)\n",
    "y0 = phi.flatten()\n",
    "#random use index \n",
    "uindex = (np.random.permutation(len(ochannel))).reshape(-1,4) #random idex of dataset\n",
    "N_labels = 1 # number of label to yield\n",
    "T = 10000 #maximum interation\n",
    "T2 = 500000 #maximum interation\n",
    "epsilon = 0.001 #threshold\n",
    "H1 = tchannel.to(device)\n",
    "H2 = torch.zeros(size=(K,Nr**2,M),dtype=torch.cdouble).to(device)\n",
    "H2pp = torch.zeros(size=(K,Nr**2,M),dtype=torch.cdouble).to(device)\n",
    "H2p = torch.zeros((K*Nr**2,M)).to(device)\n",
    "A = torch.zeros(size=(M,M),dtype=torch.cdouble).to(device)\n",
    "traceyay = torch.zeros(size=(M,M),dtype=torch.cdouble).to(device)\n",
    "deltayay = torch.zeros(M,M).to(device)\n",
    "H0 = torch.zeros(size=(K,Nr**2,Nt**2), dtype=torch.cdouble).to(device)\n",
    "yi = torch.zeros(M**2,dtype=torch.cdouble).to(device)\n",
    "\n",
    "#H1 = 1.3e-5*(torch.randn(size=(M,Nt**2),dtype=torch.cdouble)+1j*torch.randn(size=(M,Nt**2),dtype=torch.cdouble)).to(device)\n",
    "\n",
    "for t in range(N_labels):\n",
    "    index = uindex[t,:]\n",
    "    for i in range(len(index)):\n",
    "        H0[i,:,:] = 0.0002*dchannel[index[i],:,:]\n",
    "        H2[i,:,:] = (rchannel[index[i],:,:]) # K*Nr*M\n",
    "        H2pp[i,:,:] = Qinv[i,i]*H2[i,:,:]\n",
    "        H2p = H2pp.reshape(Nr**2*K,M) #NrK*M\n",
    "        H2_inv = torch.linalg.pinv(H2p)# M * N_rK\n",
    "        H1_inv = torch.linalg.pinv(H1) # Nt * M\n",
    "        H22 = (H2_inv).conj().T # # N_rK * M \n",
    "        H1_inv = H1_inv.contiguous()\n",
    "        H22 = H22.contiguous()\n",
    "        caschannel = torch.kron(H22,H1_inv)\n",
    "        A = (caschannel.conj().T) @ (caschannel)\n",
    "    yay = (y0).conj().T@(A)@(y0)\n",
    "    \n",
    "print(torch.linalg.matrix_rank(caschannel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aae6c7e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5473e+19, device='cuda:0', dtype=torch.float64)\n",
      "254707\n",
      "tensor([-0.9063+0.4227j, -0.5827-0.8127j, -0.1625+0.9867j, -0.0163+0.9999j,\n",
      "         0.7603+0.6496j, -0.8417-0.5400j, -0.9545+0.2982j, -0.9862-0.1655j,\n",
      "         0.0871+0.9962j, -0.8808+0.4735j,  0.7183+0.6958j,  0.1797+0.9837j,\n",
      "         0.0192+0.9998j, -0.5536+0.8328j,  0.9796+0.2009j, -0.0084+1.0000j,\n",
      "         0.0131+0.9999j,  0.9563+0.2923j, -0.9990+0.0457j,  0.3570+0.9341j,\n",
      "         0.9860-0.1670j, -0.5480+0.8365j,  0.4819+0.8762j,  0.7163+0.6978j,\n",
      "        -0.9406+0.3394j,  0.8137+0.5814j,  0.2693+0.9631j, -0.9118-0.4106j,\n",
      "         0.9999+0.0167j, -0.8294-0.5587j,  0.5978+0.8016j,  0.8539+0.5205j,\n",
      "         0.0525+0.9986j,  0.3273-0.9449j,  0.5043+0.8635j, -0.9579+0.2872j,\n",
      "        -0.0641+0.9979j,  0.0346+0.9994j,  0.5933-0.8050j,  0.5535+0.8329j,\n",
      "        -0.6836+0.7299j,  0.9223+0.3864j, -0.3511-0.9363j,  0.6037+0.7972j,\n",
      "        -0.4982+0.8671j,  0.6829+0.7305j,  0.8301-0.5577j,  0.3192+0.9477j,\n",
      "         0.1541+0.9881j, -0.0153+0.9999j,  0.9978+0.0665j, -0.9989+0.0468j,\n",
      "         0.1200+0.9928j, -0.6030+0.7977j, -0.4783+0.8782j,  0.5575+0.8302j,\n",
      "        -0.5476-0.8368j,  0.2862+0.9582j,  0.4248-0.9053j, -0.6069+0.7948j,\n",
      "        -0.9502+0.3118j, -0.6016+0.7988j,  0.1066+0.9943j,  0.4984+0.8669j,\n",
      "         0.9864+0.1646j,  0.2386+0.9711j,  0.8507+0.5257j, -0.3537+0.9354j,\n",
      "         0.9374-0.3481j, -0.5418+0.8405j,  0.6858-0.7278j,  0.6613+0.7501j,\n",
      "        -0.2454+0.9694j,  0.9997-0.0260j, -0.9664+0.2570j, -0.8154-0.5789j,\n",
      "         0.0563+0.9984j, -0.7823+0.6229j, -0.7082+0.7061j,  0.1836+0.9830j,\n",
      "        -0.2311+0.9729j,  0.9083-0.4183j, -0.6668+0.7453j,  0.7401-0.6725j,\n",
      "         0.9873-0.1588j,  0.5005+0.8657j, -0.0905+0.9959j, -0.9725-0.2329j,\n",
      "         0.2975+0.9547j,  0.9070-0.4210j,  0.8519+0.5238j,  0.9615+0.2749j,\n",
      "         0.2012+0.9795j,  0.3607+0.9327j, -0.4428+0.8966j, -0.5398+0.8418j,\n",
      "         0.9403-0.3403j, -0.9785+0.2061j,  0.9930-0.1180j,  0.9884+0.1521j,\n",
      "        -0.9715-0.2370j, -0.2519+0.9678j, -0.4784+0.8781j,  0.9587+0.2843j,\n",
      "        -0.4067+0.9136j, -0.7757+0.6311j, -0.1784+0.9839j, -0.0418+0.9991j,\n",
      "        -0.6391-0.7691j,  0.9043+0.4269j, -0.2671+0.9637j,  0.1860+0.9826j,\n",
      "        -0.7034+0.7108j, -0.1681+0.9858j, -0.9970-0.0777j,  0.5399+0.8417j,\n",
      "         0.5312+0.8472j, -0.5893+0.8080j,  0.0476+0.9989j, -0.8645+0.5027j,\n",
      "         0.2287+0.9735j,  0.6276+0.7786j, -0.9899+0.1419j,  0.2512+0.9679j,\n",
      "         0.5017+0.8650j,  0.0215+0.9998j,  0.5940+0.8045j, -0.6538+0.7567j],\n",
      "       device='cuda:0', dtype=torch.complex128)\n"
     ]
    }
   ],
   "source": [
    "# SPF\n",
    "lambda_max = torch.max(torch.real(torch.linalg.eigvals(A)))\n",
    "print(lambda_max)\n",
    "bigc = (lambda_max* torch.eye(M**2,M**2).to(device)-(A))\n",
    "F = torch.zeros(M,dtype=torch.cdouble).to(device)\n",
    "for tt in range(T2):\n",
    "    D = bigc @ y0\n",
    "    E = torch.diag(D.view(M,M))\n",
    "    F = e**(1j*torch.angle(E))\n",
    "    #print(torch.norm(F - torch.diag(y0.view(M,M))))\n",
    "    if torch.norm(F - torch.diag(y0.view(M,M))) < epsilon :\n",
    "        optimal_phase = F\n",
    "        break\n",
    "    else: y0 = torch.diag(F).flatten() \n",
    "print(tt)\n",
    "print(optimal_phase)\n",
    "optimal_P = torch.norm(torch.norm(H2@H1,dim=1),dim=1)/torch.sum(torch.norm(torch.norm(H2@H1,dim=1),dim=1))*Pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bfd16180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.0\n",
      "tensor([ 9.2362e-01-3.8330e-01j, -9.9036e-01-1.3848e-01j,\n",
      "        -9.7504e-01-2.2204e-01j, -9.2728e-01-3.7436e-01j,\n",
      "         9.4278e-01-3.3341e-01j, -4.3033e-01-9.0267e-01j,\n",
      "         9.6101e-01+2.7652e-01j,  6.8143e-01-7.3188e-01j,\n",
      "         9.9909e-01-4.2612e-02j,  9.9315e-01+1.1687e-01j,\n",
      "         9.7270e-01+2.3206e-01j,  6.6212e-01-7.4940e-01j,\n",
      "         8.4835e-01+5.2943e-01j, -7.5838e-01-6.5181e-01j,\n",
      "        -9.1761e-01+3.9748e-01j,  2.3549e-01-9.7188e-01j,\n",
      "         8.3294e-01-5.5337e-01j, -9.2860e-01-3.7107e-01j,\n",
      "         7.0536e-01-7.0885e-01j,  8.4578e-01-5.3353e-01j,\n",
      "         7.4470e-02-9.9722e-01j, -8.8026e-01-4.7450e-01j,\n",
      "         9.8712e-01-1.5997e-01j, -4.7759e-01-8.7858e-01j,\n",
      "         8.2339e-01-5.6748e-01j, -4.5840e-01-8.8875e-01j,\n",
      "        -9.8026e-01+1.9770e-01j,  9.6738e-01-2.5333e-01j,\n",
      "        -8.5190e-01-5.2370e-01j, -2.0245e-01-9.7929e-01j,\n",
      "         9.9928e-01+3.7908e-02j,  6.3533e-01+7.7224e-01j,\n",
      "         5.0709e-01-8.6189e-01j, -9.7992e-01+1.9939e-01j,\n",
      "         6.5195e-01-7.5827e-01j, -9.9627e-01+8.6240e-02j,\n",
      "         9.2298e-01+3.8485e-01j,  9.4352e-01-3.3131e-01j,\n",
      "        -9.1042e-01-4.1368e-01j,  9.9066e-01-1.3637e-01j,\n",
      "        -3.3810e-01-9.4111e-01j, -3.2679e-01-9.4510e-01j,\n",
      "         7.0442e-01-7.0978e-01j, -8.4839e-01-5.2937e-01j,\n",
      "         9.9974e-01-2.3015e-02j,  9.9489e-01+1.0097e-01j,\n",
      "        -9.9949e-01+3.2029e-02j, -5.5355e-01-8.3282e-01j,\n",
      "        -1.3472e-01-9.9088e-01j, -8.6124e-01-5.0820e-01j,\n",
      "        -4.5778e-01-8.8907e-01j, -5.1154e-01-8.5926e-01j,\n",
      "         9.9686e-01-7.9191e-02j, -9.7314e-01+2.3022e-01j,\n",
      "         9.2430e-01-3.8168e-01j, -1.0809e-02-9.9994e-01j,\n",
      "         9.8369e-01-1.7986e-01j,  6.8735e-01+7.2633e-01j,\n",
      "         9.3563e-01+3.5299e-01j, -9.9685e-01-7.9369e-02j,\n",
      "         1.0000e+00-5.0740e-04j,  9.7632e-01+2.1635e-01j,\n",
      "         9.9849e-01-5.4849e-02j,  8.7552e-05-1.0000e+00j,\n",
      "         6.4148e-01-7.6714e-01j, -9.6189e-02-9.9536e-01j,\n",
      "        -9.0992e-01-4.1479e-01j,  8.3591e-01+5.4887e-01j,\n",
      "         6.5889e-03-9.9998e-01j,  6.7234e-01+7.4024e-01j,\n",
      "        -4.2348e-01-9.0590e-01j, -9.8416e-01+1.7727e-01j,\n",
      "        -8.8205e-01-4.7115e-01j, -7.5121e-01+6.6006e-01j,\n",
      "        -9.4855e-01+3.1664e-01j, -7.5448e-01-6.5632e-01j,\n",
      "         9.6460e-01-2.6373e-01j, -9.7325e-01+2.2974e-01j,\n",
      "         5.0820e-01-8.6124e-01j, -1.3280e-01-9.9114e-01j,\n",
      "        -9.6045e-01+2.7845e-01j, -9.9218e-01+1.2484e-01j,\n",
      "        -7.9526e-01-6.0626e-01j, -9.8568e-01+1.6863e-01j,\n",
      "        -3.2414e-01-9.4601e-01j, -3.1899e-01+9.4776e-01j,\n",
      "        -9.3953e-01+3.4247e-01j,  2.8627e-01-9.5815e-01j,\n",
      "        -9.9480e-01+1.0185e-01j, -9.9243e-01+1.2282e-01j,\n",
      "        -9.8211e-01-1.8832e-01j, -9.3608e-01-3.5179e-01j,\n",
      "        -8.9876e-01+4.3845e-01j, -9.6660e-01+2.5628e-01j,\n",
      "         6.6652e-01+7.4549e-01j,  5.5549e-01+8.3152e-01j,\n",
      "         8.7440e-01-4.8520e-01j,  9.8950e-01+1.4453e-01j,\n",
      "        -8.5350e-01+5.2109e-01j, -9.9249e-01-1.2231e-01j,\n",
      "        -9.9732e-01+7.3115e-02j, -7.1985e-01-6.9413e-01j,\n",
      "        -9.7337e-01-2.2922e-01j,  7.6153e-01+6.4813e-01j,\n",
      "        -9.6078e-01+2.7732e-01j, -4.5203e-01+8.9200e-01j,\n",
      "        -9.9943e-01-3.3837e-02j, -5.6107e-01+8.2777e-01j,\n",
      "        -9.9938e-01-3.5280e-02j,  2.4972e-01+9.6832e-01j,\n",
      "        -9.7465e-01+2.2373e-01j, -9.9480e-01-1.0182e-01j,\n",
      "        -9.5414e-01+2.9936e-01j, -6.7632e-01-7.3661e-01j,\n",
      "        -9.9594e-01+8.9995e-02j, -9.8588e-01-1.6747e-01j,\n",
      "        -3.2155e-01-9.4689e-01j, -9.5425e-01-2.9900e-01j,\n",
      "        -9.5598e-01+2.9345e-01j, -9.9196e-01+1.2653e-01j,\n",
      "        -9.5623e-01+2.9261e-01j,  5.6029e-01-8.2830e-01j,\n",
      "        -8.9706e-01+4.4190e-01j, -9.5713e-01-2.8967e-01j,\n",
      "        -4.1348e-01+9.1051e-01j, -7.6663e-01-6.4209e-01j,\n",
      "         8.2192e-01-5.6960e-01j, -9.9752e-01-7.0315e-02j], device='cuda:0',\n",
      "       dtype=torch.complex128)\n"
     ]
    }
   ],
   "source": [
    "    #gradient based\n",
    "    for ii in range(M):\n",
    "        for jj in range(M):\n",
    "            II = (ii-1)*M+ii\n",
    "            JJ = (jj-1)*M+jj\n",
    "            traceyay[ii,jj] = A[II,JJ]\n",
    "            allelements = torch.mul(traceyay.flatten(),(torch.diag(phi)).repeat(M))\n",
    "            upper = 1j*e**(1j*(phi)[ii,jj])*torch.sum(allelements[:(int(len(allelements)/2)-1)])\n",
    "            lower = -1j*e**(-1j*(phi)[ii,jj])*torch.sum(allelements[(int(len(allelements)/2)-1):])\n",
    "            deltayay[ii,jj] = (2*torch.real(upper + lower))\n",
    "    \n",
    "    q0 = deltayay.flatten().to(device)\n",
    "    d0 = -q0.to(device)\n",
    "    yt = phi_inv.flatten().to(device)\n",
    "    for t1 in range(T):\n",
    "        t1 = t1/1\n",
    "        y1t = torch.mul(yt,d0).to(device)\n",
    "        y2t = torch.mul(y1t,d0).to(device)\n",
    "        z2 = torch.imag(yt.conj().T@A@y1t).to(device)\n",
    "        z3 = (torch.real(yt.conj().T@A@y2t)-y1t.conj().T@A@y1t).to(device)\n",
    "        ustep = (-z2/z3).to(device)\n",
    "        y_next = torch.mul(torch.mul(yt, e**(1j*ustep*d0)),(torch.eye(M).flatten()).to(device))\n",
    "        q_next = 2*torch.real(-1j*torch.mul(y_next.T, A@y_next))\n",
    "        d_next = -q_next + ((q_next-q0).T @ q_next)/((torch.norm(q0))**2)*d0\n",
    "        if q_next.T @ d_next >= 0:\n",
    "            d_next = -q_next\n",
    "        if torch.norm(y_next-yt) < epsilon :\n",
    "            optimal_phi = y_next\n",
    "            break\n",
    "        \n",
    "        yt = y_next\n",
    "        d0 = d_next\n",
    "        q0 = q_next\n",
    "        #if torch.log10(torch.abs(yt.conj().T @ A @ yt)) <= Pt:\n",
    "        optimal_P = torch.norm(torch.norm(H2@H1,dim=1),dim=1)/torch.sum(torch.norm(torch.norm(H2@H1,dim=1),dim=1))*Pt\n",
    "            #break\n",
    "        #else: optimal_P  = Pt/K\n",
    "g_phase = torch.diag(optimal_phi.view(M,M))/abs(torch.diag(optimal_phi.view(M,M)))\n",
    "print(t1)\n",
    "print(g_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "67b8cc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5386, 5.5163, 5.3926, 4.5524], device='cuda:0', dtype=torch.float64)\n",
      "gradient 9.705969202254582\n",
      "Sequential 10.335586439858162\n",
      "random 9.625451021391983\n",
      "direct only 4.536611533122023\n",
      "unit phase 10.498286267940944\n"
     ]
    }
   ],
   "source": [
    "f_phase = torch.diag(optimal_phase)\n",
    "cap_g = 0\n",
    "cap_f =0\n",
    "dlinkse =0\n",
    "randomse = 0\n",
    "onephase=0\n",
    "one = torch.diag(torch.ones(M,dtype=torch.cdouble)).to(device)\n",
    "#optimal_P = torch.sqrt(optimal_P)\n",
    "I = torch.eye(Nr**2,Nr**2).to(device)\n",
    "print(optimal_P)\n",
    "for i in range(len(optimal_P)):\n",
    "    cap_g += torch.real(torch.log2(torch.det(I+(optimal_P[i]/P_noise)*(H2[i,:,:]@torch.diag(g_phase)@H1+H0[i,:,:])@((H2[i,:,:]@torch.diag(g_phase)@H1+H0[i,:,:]).conj().T))))\n",
    "    cap_f += torch.real(torch.log2(torch.det(I+(optimal_P[i]/P_noise)*(H2[i,:,:]@f_phase@H1+H0[i,:,:])@((H2[i,:,:]@f_phase@H1+H0[i,:,:]).conj().T))))\n",
    "    dlinkse += torch.real(torch.log2(torch.det(I+(optimal_P[i]/P_noise)*(H0[i,:,:])@(H0[i,:,:]).conj().T)))\n",
    "    randomse += torch.real(torch.log2(torch.det(I+(optimal_P[i]/P_noise)*(H2[i,:,:]@rand_phi@H1+H0[i,:,:])@((H2[i,:,:]@rand_phi@H1+H0[i,:,:]).conj().T))))\n",
    "    onephase += torch.real(torch.log2(torch.det(I+(optimal_P[i]/P_noise)*(H2[i,:,:]@one@H1+H0[i,:,:])@((H2[i,:,:]@one@H1+H0[i,:,:]).conj().T))))\n",
    "print('gradient',cap_g.item())\n",
    "print('Sequential',cap_f.item())\n",
    "print('random',randomse.item())\n",
    "print('direct only',dlinkse.item())\n",
    "print('unit phase',onephase.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0cca13c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128])\n",
      "tensor(64, device='cuda:0')\n",
      "torch.Size([16, 128])\n",
      "tensor(3, device='cuda:0')\n",
      "torch.Size([1024, 16384])\n",
      "tensor(192, device='cuda:0')\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(H22.shape)\n",
    "print(torch.linalg.matrix_rank(H22))\n",
    "print(H1_inv.shape)\n",
    "print(torch.linalg.matrix_rank(H1_inv))\n",
    "print(caschannel.shape)\n",
    "print(torch.linalg.matrix_rank(caschannel))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(optimal_phase.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
